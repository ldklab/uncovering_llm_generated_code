{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "os.chdir(\"/home/yangkai/codegen-detection/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "gen_dataset = pd.read_pickle(\"dataset/csn_gpt_gen_test.pkl\")\n",
    "hum_dataset = pd.read_pickle(\"dataset/csn_1k_hum_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_json_dataset\n",
    "gen_resample_data = load_json_dataset(\"prompt_gpt/csn_gpt_gen_test_coderesample_temp07.jsonl\")\n",
    "hum_resample_data = load_json_dataset(\"prompt_gpt/csn_1k_hum_test_coderesample_temp07.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 119. No Match!\n",
      "ID: 127. No Match!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def extract_code(resp):\n",
    "    try:\n",
    "        text = resp['choices'][0]['message']['content']\n",
    "    except KeyError:\n",
    "        return ''\n",
    "    pattern = r'```python\\n(.+?)\\n```'\n",
    "    code_blocks = re.findall(pattern, text, re.DOTALL)\n",
    "    if len(code_blocks) > 0:\n",
    "        return code_blocks[0]\n",
    "\n",
    "    if resp['choices'][0]['finish_reason'] == 'length':\n",
    "        pattern2 = r'```python\\n(.+?)'\n",
    "    else:\n",
    "        pattern2 = r'``` python\\n(.+?)\\n```'\n",
    "\n",
    "    # pattern2 = r'```python\\n(.+?)'\n",
    "    code_blocks = re.findall(pattern2, text, re.DOTALL)\n",
    "    if len(code_blocks) > 0:\n",
    "        return code_blocks[0]\n",
    "\n",
    "    pattern3 = r\"```\\n(.+?)\\n```\"\n",
    "    code_blocks = re.findall(pattern3, text, re.DOTALL)\n",
    "    if len(code_blocks) > 0:\n",
    "        return code_blocks[0]\n",
    "\n",
    "    if resp['choices'][0]['finish_reason'] == 'length':\n",
    "        pattern4 = r\"```\\n(.+?)\"\n",
    "        code_blocks = re.findall(pattern4, text, re.DOTALL)\n",
    "        if len(code_blocks) > 0:\n",
    "            return code_blocks[0]\n",
    "\n",
    "    # pattern4 = r\"```\\n(.+?)\"\n",
    "    # code_blocks = re.findall(pattern4, text, re.DOTALL)\n",
    "    # if len(code_blocks) > 0:\n",
    "    #     return code_blocks[0]\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "extracted_gen_code = []\n",
    "cnt = 0\n",
    "for i,resp in enumerate(gen_resample_data):\n",
    "    code = extract_code(resp)\n",
    "    if len(code) == 0:\n",
    "        print(f\"ID: {i}. No Match!\")\n",
    "        cnt += 1\n",
    "    extracted_gen_code.append(code)\n",
    "\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepro.code_prepro import CommentsRemover,PygmentsTokenizer,EmptyLinesRemover\n",
    "tokenizer = PygmentsTokenizer('Python')\n",
    "comment_remover = CommentsRemover(tokenizer)\n",
    "emptyline_remover = EmptyLinesRemover()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dataset['gpt_resampled_code'] = gen_resample_data\n",
    "# hum_dataset['gpt_resampled_code2'] = hum_resample_data\n",
    "\n",
    "gen_dataset['gpt_resampled_code'] = gen_dataset['gpt_resampled_code'].apply(extract_code)\n",
    "# hum_dataset['gpt_resampled_code2'] = hum_dataset['gpt_resampled_code2'].apply(extract_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = gen_dataset.gpt_resampled_code.apply(comment_remover.filter)\n",
    "gen_dataset['gpt_resampled_code_cleaned'] = temp.apply(emptyline_remover.filter)\n",
    "\n",
    "# temp = hum_dataset.gpt_resampled_code2.apply(comment_remover.filter)\n",
    "# hum_dataset['gpt_resampled_code_cleaned2'] = temp.apply(emptyline_remover.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>extracted_full_func</th>\n",
       "      <th>temp</th>\n",
       "      <th>prompt</th>\n",
       "      <th>pid</th>\n",
       "      <th>gpt_resampled_code</th>\n",
       "      <th>gpt_resampled_code_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>import string\\nfrom collections import Counter...</td>\n",
       "      <td>import string\\nfrom collections import Counter...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>def correct_word(word_string):\\n    '''\\n    F...</td>\n",
       "      <td>0</td>\n",
       "      <td>import re\\nfrom collections import defaultdict...</td>\n",
       "      <td>import re\\nfrom collections import defaultdict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def find_word_prob(word_string, word_total=sum...</td>\n",
       "      <td>def find_word_prob(word_string, word_total=sum...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>def find_word_prob(word_string, word_total=sum...</td>\n",
       "      <td>1</td>\n",
       "      <td>def find_word_prob(word_string, word_distribut...</td>\n",
       "      <td>def find_word_prob(word_string, word_distribut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def kmeans_clustering(self, numc, X=None, npcs...</td>\n",
       "      <td>def kmeans_clustering(self, numc, X=None, npcs...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>def kmeans_clustering(self, numc, X=None, npcs...</td>\n",
       "      <td>2</td>\n",
       "      <td>from sklearn.cluster import KMeans\\nfrom sklea...</td>\n",
       "      <td>from sklearn.cluster import KMeans\\nfrom sklea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>import tempfile\\n\\ndef _tmp_html_file(self, co...</td>\n",
       "      <td>import tempfile\\ndef _tmp_html_file(self, cont...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>def _tmp_html_file(\\n            self,\\n      ...</td>\n",
       "      <td>3</td>\n",
       "      <td>import tempfile\\n\\ndef create_tmp_html_file(co...</td>\n",
       "      <td>import tempfile\\ndef create_tmp_html_file(cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def sort_numpy(array, col=0, order_back=False)...</td>\n",
       "      <td>def sort_numpy(array, col=0, order_back=False)...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>def sort_numpy(array, col=0, order_back=False)...</td>\n",
       "      <td>4</td>\n",
       "      <td>def sort_numpy(array, col=0, order_back=False)...</td>\n",
       "      <td>def sort_numpy(array, col=0, order_back=False)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>from fuzzywuzzy import fuzz\\n\\ndef fuzzmatch(s...</td>\n",
       "      <td>from fuzzywuzzy import fuzz\\ndef fuzzmatch(sel...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>def fuzzmatch(self, fuzzkey, multi=False):\\n  ...</td>\n",
       "      <td>249</td>\n",
       "      <td>from fuzzywuzzy import process\\n\\ndef fuzzy_ma...</td>\n",
       "      <td>from fuzzywuzzy import process\\ndef fuzzy_matc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>import zipfile\\nimport os\\n\\ndef extract_zipdi...</td>\n",
       "      <td>import zipfile\\nimport os\\ndef extract_zipdir(...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>def extract_zipdir(zip_file):\\n    \"\"\"\\n    Ex...</td>\n",
       "      <td>250</td>\n",
       "      <td>import shutil\\nimport os\\n\\ndef extract_zipdir...</td>\n",
       "      <td>import shutil\\nimport os\\ndef extract_zipdir(z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>def read_field_report(path, data_flag=\"*DATA\",...</td>\n",
       "      <td>def read_field_report(path, data_flag=\"*DATA\",...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>def read_field_report(path, data_flag = \"*DATA...</td>\n",
       "      <td>251</td>\n",
       "      <td>def read_field_report(path, data_flag=\"*DATA\",...</td>\n",
       "      <td>def read_field_report(path, data_flag=\"*DATA\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>import html\\n\\ndef escape(t):\\n    \"\"\"\\n    HT...</td>\n",
       "      <td>import html\\ndef escape(t):\\n    return html.e...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>def escape(t):\\n    \"\"\"HTML-escape the text in...</td>\n",
       "      <td>252</td>\n",
       "      <td>import cgi\\n\\ndef escape(t):\\n    return cgi.e...</td>\n",
       "      <td>import cgi\\ndef escape(t):\\n    return cgi.esc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>def uniq_stable(elems):\\n    \"\"\"uniq_stable(el...</td>\n",
       "      <td>def uniq_stable(elems):\\n    seen = {}\\n    re...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>def uniq_stable(elems):\\n    \"\"\"uniq_stable(el...</td>\n",
       "      <td>253</td>\n",
       "      <td>def uniq_stable(elems):\\n    return [elem for ...</td>\n",
       "      <td>def uniq_stable(elems):\\n    return [elem for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  code  \\\n",
       "0    import string\\nfrom collections import Counter...   \n",
       "1    def find_word_prob(word_string, word_total=sum...   \n",
       "2    def kmeans_clustering(self, numc, X=None, npcs...   \n",
       "3    import tempfile\\n\\ndef _tmp_html_file(self, co...   \n",
       "4    def sort_numpy(array, col=0, order_back=False)...   \n",
       "..                                                 ...   \n",
       "249  from fuzzywuzzy import fuzz\\n\\ndef fuzzmatch(s...   \n",
       "250  import zipfile\\nimport os\\n\\ndef extract_zipdi...   \n",
       "251  def read_field_report(path, data_flag=\"*DATA\",...   \n",
       "252  import html\\n\\ndef escape(t):\\n    \"\"\"\\n    HT...   \n",
       "253  def uniq_stable(elems):\\n    \"\"\"uniq_stable(el...   \n",
       "\n",
       "                                   extracted_full_func  temp  \\\n",
       "0    import string\\nfrom collections import Counter...   0.7   \n",
       "1    def find_word_prob(word_string, word_total=sum...   0.7   \n",
       "2    def kmeans_clustering(self, numc, X=None, npcs...   0.7   \n",
       "3    import tempfile\\ndef _tmp_html_file(self, cont...   0.7   \n",
       "4    def sort_numpy(array, col=0, order_back=False)...   0.7   \n",
       "..                                                 ...   ...   \n",
       "249  from fuzzywuzzy import fuzz\\ndef fuzzmatch(sel...   0.7   \n",
       "250  import zipfile\\nimport os\\ndef extract_zipdir(...   0.7   \n",
       "251  def read_field_report(path, data_flag=\"*DATA\",...   0.7   \n",
       "252  import html\\ndef escape(t):\\n    return html.e...   0.7   \n",
       "253  def uniq_stable(elems):\\n    seen = {}\\n    re...   0.7   \n",
       "\n",
       "                                                prompt  pid  \\\n",
       "0    def correct_word(word_string):\\n    '''\\n    F...    0   \n",
       "1    def find_word_prob(word_string, word_total=sum...    1   \n",
       "2    def kmeans_clustering(self, numc, X=None, npcs...    2   \n",
       "3    def _tmp_html_file(\\n            self,\\n      ...    3   \n",
       "4    def sort_numpy(array, col=0, order_back=False)...    4   \n",
       "..                                                 ...  ...   \n",
       "249  def fuzzmatch(self, fuzzkey, multi=False):\\n  ...  249   \n",
       "250  def extract_zipdir(zip_file):\\n    \"\"\"\\n    Ex...  250   \n",
       "251  def read_field_report(path, data_flag = \"*DATA...  251   \n",
       "252  def escape(t):\\n    \"\"\"HTML-escape the text in...  252   \n",
       "253  def uniq_stable(elems):\\n    \"\"\"uniq_stable(el...  253   \n",
       "\n",
       "                                    gpt_resampled_code  \\\n",
       "0    import re\\nfrom collections import defaultdict...   \n",
       "1    def find_word_prob(word_string, word_distribut...   \n",
       "2    from sklearn.cluster import KMeans\\nfrom sklea...   \n",
       "3    import tempfile\\n\\ndef create_tmp_html_file(co...   \n",
       "4    def sort_numpy(array, col=0, order_back=False)...   \n",
       "..                                                 ...   \n",
       "249  from fuzzywuzzy import process\\n\\ndef fuzzy_ma...   \n",
       "250  import shutil\\nimport os\\n\\ndef extract_zipdir...   \n",
       "251  def read_field_report(path, data_flag=\"*DATA\",...   \n",
       "252  import cgi\\n\\ndef escape(t):\\n    return cgi.e...   \n",
       "253  def uniq_stable(elems):\\n    return [elem for ...   \n",
       "\n",
       "                            gpt_resampled_code_cleaned  \n",
       "0    import re\\nfrom collections import defaultdict...  \n",
       "1    def find_word_prob(word_string, word_distribut...  \n",
       "2    from sklearn.cluster import KMeans\\nfrom sklea...  \n",
       "3    import tempfile\\ndef create_tmp_html_file(cont...  \n",
       "4    def sort_numpy(array, col=0, order_back=False)...  \n",
       "..                                                 ...  \n",
       "249  from fuzzywuzzy import process\\ndef fuzzy_matc...  \n",
       "250  import shutil\\nimport os\\ndef extract_zipdir(z...  \n",
       "251  def read_field_report(path, data_flag=\"*DATA\",...  \n",
       "252  import cgi\\ndef escape(t):\\n    return cgi.esc...  \n",
       "253  def uniq_stable(elems):\\n    return [elem for ...  \n",
       "\n",
       "[254 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dataset.to_pickle(\"dataset/csn_gpt_gen_test.pkl\")\n",
    "# hum_dataset.to_pickle(\"dataset/csn_1k_hum_test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38-torch113",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
