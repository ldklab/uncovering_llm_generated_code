{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry_with_exponential_backoff(\n",
    "    func,\n",
    "    initial_delay: float = 5,\n",
    "    exponential_base: float = 2,\n",
    "    jitter: bool = True,\n",
    "    max_retries: int = 5,\n",
    "):\n",
    "    \"\"\"Retry a function with exponential backoff.\"\"\"\n",
    "\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # Initialize variables\n",
    "        num_retries = 0\n",
    "        delay = initial_delay\n",
    "\n",
    "        # Loop until a successful response or max_retries is hit or an exception is raised\n",
    "        while True:\n",
    "            response = func(*args, **kwargs)\n",
    "\n",
    "            # Retry on specified errors\n",
    "            if response['message'] != \"success\":\n",
    "                # Increment retries\n",
    "                num_retries += 1\n",
    "\n",
    "                # Check if max retries has been reached\n",
    "                if num_retries > max_retries:\n",
    "                    raise Exception(\"Maximum Retry Exceed\")\n",
    "\n",
    "                # Increment the delay\n",
    "                delay *= exponential_base * (1 + jitter * random.random())\n",
    "\n",
    "                # Sleep for the delay\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                return response\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "@retry_with_exponential_backoff\n",
    "def prompt_codegeex(prompt, temperature, top_p=None, n=5):\n",
    "    \"\"\"Make an api call to ChatGPT and write the respone to a file\"\"\"\n",
    "    api_url = \"https://wudao.aminer.cn/os/api/api/v2/multilingual_code/generate\"\n",
    "    # api_url = \"https://maas.aminer.cn/api/paas/model/v2/open/engines/code-generate-block/codegeex-generate-block\"\n",
    "    \n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\"lang\": \"Python\",\n",
    "            \"prompt\": f\"# language: Python\\n\\n{prompt}\",\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"n\":n}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, json=data)\n",
    "    except requests.exceptions as err:\n",
    "        print(err)\n",
    "        raise Exception(\"Error in Connection...\")\n",
    "\n",
    "    json_response = response.json()\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_json_dataset\n",
    "he_data = load_json_dataset(\"dataset/humaneval/HumanEval.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to dataset/humaneval/codegeex_13B-0.8-1.0-350-3_response.json\n"
     ]
    }
   ],
   "source": [
    "model_name = \"codegeex-13B\"\n",
    "max_tokens = 350\n",
    "temperature = 0.8\n",
    "top_p = 1.0\n",
    "n = 3\n",
    "output_file_pth = f\"dataset/humaneval/{model_name.replace('-','_')}-{temperature}-{top_p}-{max_tokens}-{n}_response.json\"\n",
    "# out_file = open(output_file_pth, \"a\")\n",
    "print(f\"write to {output_file_pth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['    if len(numbers) < 3:\\n        return False\\n    min_distances = [abs(a - b) for a, b in zip(numbers[1:], numbers[:-1])]\\n    return all(\\n        distance < threshold for distance in min_distances\\n    )\\n', '    if len(numbers) < 2:\\n        return False\\n    # TODO: improve to be O(n^2)\\n    for i in range(len(numbers) - 1):\\n        j = i + 1\\n        while j < len(numbers):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n            j += 1\\n    return False\\n', '    if len(numbers) < 3:\\n        return False\\n    numbers.sort()\\n    return numbers[1] - numbers[0] <= threshold and numbers[-1] - numbers[-2] <= threshold\\n']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 1/2 [00:23<00:23, 23.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"    separated_groups = []\\n    paren_indexes = []\\n    for char in paren_string:\\n        if char == '(':\\n            paren_indexes.append(len(separated_groups))\\n        elif char == ')':\\n            if len(paren_indexes) > 0:\\n                paren_indexes.pop()\\n            else:\\n                return []\\n        else:\\n            if len(paren_indexes) == 0:\\n                separated_groups.append(char)\\n            elif char!='':\\n                separated_groups[paren_indexes[-1]] += char\\n    return separated_groups\\n\", \"    separated_groups = []\\n    in_curly_brace_group = False\\n    in_paren_group = False\\n    for ch in paren_string:\\n        if in_curly_brace_group:\\n            if ch == '}':\\n                in_curly_brace_group = False\\n            else:\\n                separated_groups.append(ch)\\n        elif ch == '{':\\n            in_curly_brace_group = True\\n        elif ch == '(' and not in_paren_group:\\n            separated_groups.append(ch)\\n            in_paren_group = True\\n        elif ch == ')' and not in_curly_brace_group:\\n            separated_groups.append(ch)\\n            in_paren_group = False\\n        else:\\n            separated_groups.append(ch)\\n    return separated_groups\\n\", \"    output: List[str] = []\\n    for i, char in enumerate(paren_string):\\n        if char == '(':\\n            left_group: List[str] = []\\n            right_group: List[str] = []\\n            while paren_string[i]!= ')':\\n                left_group.append(paren_string[i])\\n                i+=1\\n            output.append(''.join(left_group))\\n            while paren_string[i]!= ')':\\n                i+=1\\n            i+=1\\n            while paren_string[i]!= '(':\\n                right_group.append(paren_string[i])\\n                i+=1\\n            output.append(''.join(right_group))\\n        elif char =='':\\n            output.append(char)\\n        else:\\n            pass\\n    return output\\n\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [01:27<00:00, 43.93s/it]\n"
     ]
    }
   ],
   "source": [
    "def generate_block(prompt, gen, temperature, top_p=None):\n",
    "    response = prompt_codegeex(prompt+gen, temperature, top_p=top_p, n=1)\n",
    "    try_cnt = 1\n",
    "    while (len(response['result']['output']['code']) > 0 and\n",
    "           response['result']['output']['code'][0] != \"\" and try_cnt < max_try_limit):\n",
    "        gen = gen + response['result']['output']['code'][0]\n",
    "        response = prompt_codegeex(prompt+gen, temperature, top_p=top_p, n=1)\n",
    "        try_cnt += 1\n",
    "\n",
    "    return gen\n",
    "\n",
    "for data in tqdm.tqdm(he_data[:2]):\n",
    "    prompt = f\"{data['prompt']}\"\n",
    "    first_response = prompt_codegeex(prompt, temperature, top_p=top_p, n=n)\n",
    "    max_try_limit = 25\n",
    "    gen_code = []\n",
    "    for first_gen in first_response['result']['output']['code']:\n",
    "        gen_code.append(generate_block(prompt, first_gen, temperature, top_p=top_p))\n",
    "    \n",
    "    data['raw_response'] = gen_code\n",
    "    # out_file.write(json.dumps(data) + \"\\n\")\n",
    "    print(gen_code)\n",
    "    time.sleep(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    output: List[str] = []\n",
      "    for i, char in enumerate(paren_string):\n",
      "        if char == '(':\n",
      "            left_group: List[str] = []\n",
      "            right_group: List[str] = []\n",
      "            while paren_string[i]!= ')':\n",
      "                left_group.append(paren_string[i])\n",
      "                i+=1\n",
      "            output.append(''.join(left_group))\n",
      "            while paren_string[i]!= ')':\n",
      "                i+=1\n",
      "            i+=1\n",
      "            while paren_string[i]!= '(':\n",
      "                right_group.append(paren_string[i])\n",
      "                i+=1\n",
      "            output.append(''.join(right_group))\n",
      "        elif char =='':\n",
      "            output.append(char)\n",
      "        else:\n",
      "            pass\n",
      "    return output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gen_code[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ddbd7fc550650fda5ec63b9fadd14ab8ea70de3e67f7e9e45459c9a693fe0ac4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}