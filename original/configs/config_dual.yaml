seed: 44
mode: offline
tags:
  - bertcls
batch_size: 8
simulate_batch_size: 32
valid_batch_size: 32
gradient_norm_clip_value: 1.0
n_epoch: 5
decay: 3e-4
lr: 1e-4
warmup: 0.1
device: 1

data:
  mini_dataset: false
  max_input_len: 512
  tokenizer_pth1: "microsoft/graphcodebert-base"
  tokenizer_pth2: "roberta-base"
  input_key1: extracted_full_func
  input_key2: vicuna_explain
  train_frac: 1.0

model:
  plm_name1: "microsoft/graphcodebert-base"
  plm_name2: "microsoft/graphcodebert-base"
  cls_drop: 0.2
  cls_dim: 768
  save_pth: none

defaults:
  - setting: apps_full